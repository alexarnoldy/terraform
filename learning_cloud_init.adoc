
== Cloud Init 
 
==== Review module execution order: /etc/cloud/cloud.cfg
* Good, basic explanation: https://stackoverflow.com/questions/34095839/cloud-init-what-is-the-execution-order-of-cloud-config-directives 
* bootcmd (and possibly all cloud_init_modules) run on every boot
* Seems like the cloud_config_modules and cloud_final_modules only run on first boot
* Can make a module (scripts-user in this example) run on every boot my changing from `- scripts-user` to `- [scripts-user, always]`
* I.e. (Should work but haven't tested) In the cloud-init file that is passed to the target system, include:

----
cloud_final_modules:
 - rightscale_userdata
 - scripts-per-once
 - scripts-per-boot
 - scripts-per-instance
 - [scripts-user, always]
 - keys-to-console
 - phone-home
 - final-message
----
 
 ** Should be able to specify only the modules that are needed

* Scripts that are populated in `/var/lib/cloud/scripts/per-boot/` will run on every boot

* Seems like the scripts/per-boot/ didn't wait for runcmd to finish before running (or perhaps was called before runcmd)

IMPORTANT: To get the desired effect of 1)update software and kernel, 2) reboot, 3)run cluster configuration script *as* *user* *sles*; had to a)use write-files to put deploy_cluster.sh and recover_deployment.sh in /tmp and in /root, respectively (recover_deployment.sh is basically just one line: `sudo -H -u sles bash /tmp/deploy_caasp.sh` ), b)in runcmd include `- cp -p /root/recover_deployment.sh /var/lib/cloud/scripts/per-boot/` just before `- reboot`, c)make deploy_caasp.sh idempotent by having it exit if it finds a directory under /home/sles with the name of the cluster, which is direvied from the /home/sles/.all_nodes file. Might have gotten there easier by using `scripts-per-once` but didnt' have time to explore.

==== Base64 encoding a file to be inserted by cloud_init seems to preserve formatting, such as leading spaces 
* Encode with: `cat <file> | base64 | awk '{print}' ORS='' && echo` 
* In the cloud init file: 
---- 
  - path: <absolute path name of file 
    encoding: b64 
    permissions: "0644" 
    content: <encoded content> 
---- 
 
==== NTP should be configured in TF but doesn't seem to be for libvirt
* Can always just do it in cloud_init
----
ntp:
  enabled: true
  ntp_client: chrony
  pools: [0.pool.ntp.org, 1.pool.ntp.org, 2.pool.ntp.org]
----

==== Running scripts
* Currently putting them under runcmd so they run only when the instance is first created
* Always run as root. To run as another users: `sudo -H -u <user> bash <absolute path to script>`
** Use same but `bash -c <commands>` to run loose commands

==== Maintaining variables between TF and cloud init
* First must be declared in variables.tf, such as:
----
variable "username" {
  default     = "sles"
  description = "Username for the cluster nodes"
}

variable "password" {
  default     = "linux"
  description = "Password for the cluster nodes"
}
----

* Then needs a block in the <file>.tf, such as:
----
data "template_file" "admin_cloud_init_user_data" {
  vars = {
    username        = var.username
    password        = var.password
  }
}
----
* Use in cloud-init file with `${username}`
 

// vim: set syntax=asciidoc:
